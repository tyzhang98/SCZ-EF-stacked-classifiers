{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.缓解组与未缓解组基线水平临床量表差异性检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality Test Results (Shapiro-Wilk):\n",
      "PANSS-N(1):\n",
      "    Group 1: W-statistic=0.986, p-value=0.721\n",
      "    Group 2: W-statistic=0.951, p-value=0.208\n",
      "PANSS-P(1):\n",
      "    Group 1: W-statistic=0.978, p-value=0.389\n",
      "    Group 2: W-statistic=0.871, p-value=0.003\n",
      "PANSS-G(1):\n",
      "    Group 1: W-statistic=0.935, p-value=0.004\n",
      "    Group 2: W-statistic=0.887, p-value=0.006\n",
      "PANSS-T(1):\n",
      "    Group 1: W-statistic=0.947, p-value=0.013\n",
      "    Group 2: W-statistic=0.825, p-value=0.000\n",
      "Baseline_Negative:\n",
      "    Group 1: W-statistic=0.968, p-value=0.127\n",
      "    Group 2: W-statistic=0.945, p-value=0.144\n",
      "Baseline_Positive:\n",
      "    Group 1: W-statistic=0.971, p-value=0.188\n",
      "    Group 2: W-statistic=0.929, p-value=0.057\n",
      "Baseline_Affective:\n",
      "    Group 1: W-statistic=0.961, p-value=0.058\n",
      "    Group 2: W-statistic=0.972, p-value=0.640\n",
      "Baseline_Cognitive:\n",
      "    Group 1: W-statistic=0.957, p-value=0.038\n",
      "    Group 2: W-statistic=0.884, p-value=0.005\n",
      "\n",
      "Homogeneity of Variance Test Results (Levene's Test):\n",
      "PANSS-N(1): Levene Statistic = 0.881, p-value = 0.351\n",
      "PANSS-P(1): Levene Statistic = 2.396, p-value = 0.125\n",
      "PANSS-G(1): Levene Statistic = 1.074, p-value = 0.303\n",
      "PANSS-T(1): Levene Statistic = 0.209, p-value = 0.649\n",
      "Baseline_Negative: Levene Statistic = 3.092, p-value = 0.082\n",
      "Baseline_Positive: Levene Statistic = 2.528, p-value = 0.116\n",
      "Baseline_Affective: Levene Statistic = 2.233, p-value = 0.139\n",
      "Baseline_Cognitive: Levene Statistic = 1.063, p-value = 0.305\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "file_path = 'rawdata/缓解与未缓解.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "columns_to_compare = [\n",
    "    'PANSS-N(1)', 'PANSS-P(1)', 'PANSS-G(1)', 'PANSS-T(1)',\n",
    "    'Baseline_Negative', 'Baseline_Positive', 'Baseline_Affective', 'Baseline_Cognitive'\n",
    "]\n",
    "\n",
    "group1 = data[data['Group'] == 1]\n",
    "group2 = data[data['Group'] == 2]\n",
    "\n",
    "normality_results = {}\n",
    "homogeneity_results = {}\n",
    "\n",
    "for column in columns_to_compare:\n",
    "    normality_results[column] = {\n",
    "        'Group 1': stats.shapiro(group1[column]),\n",
    "        'Group 2': stats.shapiro(group2[column])\n",
    "    }\n",
    "    \n",
    "\n",
    "    stat, p_value = stats.levene(group1[column], group2[column])\n",
    "    homogeneity_results[column] = {'Levene Statistic': stat, 'p-value': p_value}\n",
    "\n",
    "print(\"Normality Test Results (Shapiro-Wilk):\")\n",
    "for column in normality_results:\n",
    "    print(f\"{column}:\")\n",
    "    print(f\"    Group 1: W-statistic={normality_results[column]['Group 1'][0]:.3f}, p-value={normality_results[column]['Group 1'][1]:.3f}\")\n",
    "    print(f\"    Group 2: W-statistic={normality_results[column]['Group 2'][0]:.3f}, p-value={normality_results[column]['Group 2'][1]:.3f}\")\n",
    "\n",
    "print(\"\\nHomogeneity of Variance Test Results (Levene's Test):\")\n",
    "for column in homogeneity_results:\n",
    "    print(f\"{column}: Levene Statistic = {homogeneity_results[column]['Levene Statistic']:.3f}, p-value = {homogeneity_results[column]['p-value']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Variable | Group 1 Mean ± Std | Group 2 Mean ± Std | t | p | d |\n",
      "|----------|--------------------|--------------------|---|---|-----------|\n",
      "| PANSS-N(1) | 21.59 ± 6.59 | 21.79 ± 5.99 | -0.14 | 0.889 | -0.03 |\n",
      "| PANSS-P(1) | 21.64 ± 4.06 | 21.18 ± 5.99 | 0.37 | 0.715 | 0.10 |\n",
      "| PANSS-G(1) | 39.67 ± 7.39 | 40.39 ± 6.20 | -0.47 | 0.637 | -0.10 |\n",
      "| PANSS-T(1) | 82.90 ± 13.97 | 83.36 ± 15.33 | -0.13 | 0.894 | -0.03 |\n",
      "| Baseline_Negative | 8.24 ± 2.70 | 8.71 ± 2.11 | -0.87 | 0.385 | -0.18 |\n",
      "| Baseline_Positive | 5.99 ± 1.66 | 6.23 ± 2.07 | -0.54 | 0.591 | -0.13 |\n",
      "| Baseline_Affective | 5.67 ± 0.93 | 5.57 ± 0.78 | 0.53 | 0.598 | 0.11 |\n",
      "| Baseline_Cognitive | 9.66 ± 1.82 | 9.76 ± 1.61 | -0.24 | 0.815 | -0.05 |\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cohen_d(x, y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)\n",
    "\n",
    "t_test_results = {}\n",
    "\n",
    "for column in columns_to_compare:\n",
    "    t_stat, p_val = stats.ttest_ind(group1[column], group2[column], equal_var=False)  # 使用 Welch's t-test\n",
    "    \n",
    "    d_val = cohen_d(group1[column], group2[column])\n",
    "    \n",
    "    t_test_results[column] = {\n",
    "        'Group 1 Mean': group1[column].mean(),\n",
    "        'Group 1 Std': group1[column].std(ddof=1),\n",
    "        'Group 2 Mean': group2[column].mean(),\n",
    "        'Group 2 Std': group2[column].std(ddof=1),\n",
    "        't-statistic': t_stat,\n",
    "        'p-value': p_val,\n",
    "        'd': d_val\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"| Variable | Group 1 Mean ± Std | Group 2 Mean ± Std | t | p | d |\")\n",
    "print(\"|----------|--------------------|--------------------|---|---|-----------|\")\n",
    "for column, result in t_test_results.items():\n",
    "    print(\n",
    "        f\"| {column} | \"\n",
    "        f\"{result['Group 1 Mean']:.2f} ± {result['Group 1 Std']:.2f} | \"\n",
    "        f\"{result['Group 2 Mean']:.2f} ± {result['Group 2 Std']:.2f} | \"\n",
    "        f\"{result['t-statistic']:.2f} | \"\n",
    "        f\"{result['p-value']:.3f} | \"\n",
    "        f\"{result['d']:.2f} |\"  \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.增加描述统计-推断统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.一般信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Field Name                                     | All Samples    | Followed Up    | Lost to Follow-Up   | Remission      | No Remission   |\n",
      "|:-----------------------------------------------|:---------------|:---------------|:--------------------|:---------------|:---------------|\n",
      "| PANSS_Negative                                 | 8.22 ± 2.50    | 8.38 ± 2.53    | 8.09 ± 2.49         | 8.23 ± 2.70    | 8.68 ± 2.13    |\n",
      "| PANSS_Positive                                 | 6.24 ± 1.75    | 6.07 ± 1.79    | 6.37 ± 1.70         | 6.05 ± 1.68    | 6.13 ± 2.04    |\n",
      "| PANSS_Affective                                | 5.65 ± 0.86    | 5.63 ± 0.88    | 5.67 ± 0.85         | 5.66 ± 0.92    | 5.58 ± 0.79    |\n",
      "| PANSS_Cognitive                                | 9.78 ± 1.72    | 9.68 ± 1.74    | 9.86 ± 1.71         | 9.64 ± 1.82    | 9.75 ± 1.61    |\n",
      "| PANSS-N                                        | 21.42 ± 6.50   | 21.76 ± 6.37   | 21.15 ± 6.62        | 21.53 ± 6.83   | 22.21 ± 5.37   |\n",
      "| PANSS-P                                        | 22.01 ± 4.47   | 21.57 ± 4.71   | 22.35 ± 4.26        | 21.69 ± 4.24   | 21.32 ± 5.65   |\n",
      "| PANSS-G                                        | 40.30 ± 6.83   | 40.07 ± 6.90   | 40.48 ± 6.80        | 39.72 ± 7.53   | 40.79 ± 5.39   |\n",
      "| Age                                            | 35.35 ± 9.35   | 34.47 ± 8.93   | 36.05 ± 9.66        | 34.33 ± 8.70   | 34.75 ± 9.56   |\n",
      "| Education_years                                | 11.12 ± 4.57   | 10.70 ± 4.05   | 11.46 ± 4.93        | 10.28 ± 3.81   | 11.57 ± 4.44   |\n",
      "| BMI                                            | 23.66 ± 3.73   | 23.21 ± 3.38   | 24.01 ± 3.97        | 23.48 ± 3.16   | 22.66 ± 3.79   |\n",
      "| SES                                            | 23.21 ± 7.32   | 22.88 ± 7.44   | 23.47 ± 7.26        | 22.52 ± 7.30   | 23.64 ± 7.79   |\n",
      "| RPM                                            | 32.56 ± 11.50  | 34.15 ± 11.67  | 31.31 ± 11.27       | 34.79 ± 11.21  | 32.82 ± 12.67  |\n",
      "| Frequency of episodes                          | 5.98 ± 4.27    | 6.22 ± 3.89    | 5.80 ± 4.56         | 6.17 ± 3.84    | 6.32 ± 4.05    |\n",
      "| Age of onset                                   | 27.43 ± 8.63   | 27.08 ± 8.46   | 27.71 ± 8.79        | 26.71 ± 7.94   | 27.86 ± 9.56   |\n",
      "| Illness of duration (months)                   | 116.92 ± 85.99 | 114.50 ± 78.09 | 118.83 ± 92.06      | 109.05 ± 71.78 | 125.79 ± 90.14 |\n",
      "| Illness of duration (years)                    | 9.74 ± 7.17    | 9.54 ± 6.51    | 9.90 ± 7.67         | 9.09 ± 5.98    | 10.48 ± 7.51   |\n",
      "| Dose Equivalent to Olanzapine (mg/d)           | 14.48 ± 6.41   | 15.07 ± 6.31   | 14.02 ± 6.47        | 14.30 ± 5.46   | 16.65 ± 7.66   |\n",
      "| ('Gender', 1)                                  | 114 (58.46%)   | 53 (61.63%)    | 61 (55.96%)         | 39 (67.24%)    | 14 (50.0%)     |\n",
      "| ('Gender', 2)                                  | 81 (41.54%)    | 33 (38.37%)    | 48 (44.04%)         | 19 (32.76%)    | 14 (50.0%)     |\n",
      "| ('Ethnic', 1)                                  | 173 (88.72%)   | 77 (89.53%)    | 96 (88.07%)         | 53 (91.38%)    | 24 (85.71%)    |\n",
      "| ('Ethnic', 2)                                  | 22 (11.28%)    | 9 (10.47%)     | 13 (11.93%)         | 5 (8.62%)      | 4 (14.29%)     |\n",
      "| ('Residence', 1)                               | 114 (58.46%)   | 44 (51.16%)    | 70 (64.22%)         | 27 (46.55%)    | 17 (60.71%)    |\n",
      "| ('Residence', 2)                               | 81 (41.54%)    | 42 (48.84%)    | 39 (35.78%)         | 31 (53.45%)    | 11 (39.29%)    |\n",
      "| ('Only_child', 2)                              | 132 (67.69%)   | 56 (65.12%)    | 76 (69.72%)         | 41 (70.69%)    | 15 (53.57%)    |\n",
      "| ('Only_child', 1)                              | 63 (32.31%)    | 30 (34.88%)    | 33 (30.28%)         | 17 (29.31%)    | 13 (46.43%)    |\n",
      "| ('Smoking_status', 1)                          | 119 (61.03%)   | 54 (62.79%)    | 65 (59.63%)         | 34 (58.62%)    | 20 (71.43%)    |\n",
      "| ('Smoking_status', 3)                          | 57 (29.23%)    | 24 (27.91%)    | 33 (30.28%)         | 18 (31.03%)    | 6 (21.43%)     |\n",
      "| ('Smoking_status', 2)                          | 19 (9.74%)     | 8 (9.3%)       | 11 (10.09%)         | 6 (10.34%)     | 2 (7.14%)      |\n",
      "| ('Alcohol_consumption', 1)                     | 133 (68.21%)   | 60 (69.77%)    | 73 (66.97%)         | 40 (68.97%)    | 20 (71.43%)    |\n",
      "| ('Alcohol_consumption', 2)                     | 54 (27.69%)    | 23 (26.74%)    | 31 (28.44%)         | 16 (27.59%)    | 7 (25.0%)      |\n",
      "| ('Alcohol_consumption', 3)                     | 8 (4.1%)       | 3 (3.49%)      | 5 (4.59%)           | 2 (3.45%)      | 1 (3.57%)      |\n",
      "| ('Employed', 2)                                | 142 (72.82%)   | 66 (76.74%)    | 76 (69.72%)         | 43 (74.14%)    | 23 (82.14%)    |\n",
      "| ('Employed', 1)                                | 53 (27.18%)    | 20 (23.26%)    | 33 (30.28%)         | 15 (25.86%)    | 5 (17.86%)     |\n",
      "| ('Marital_status', 1)                          | 115 (58.97%)   | 52 (60.47%)    | 63 (57.8%)          | 34 (58.62%)    | 18 (64.29%)    |\n",
      "| ('Marital_status', 2)                          | 48 (24.62%)    | 21 (24.42%)    | 27 (24.77%)         | 17 (29.31%)    | 4 (14.29%)     |\n",
      "| ('Marital_status', 3)                          | 31 (15.9%)     | 13 (15.12%)    | 18 (16.51%)         | 7 (12.07%)     | 6 (21.43%)     |\n",
      "| ('Marital_status', 4)                          | 1 (0.51%)      | nan            | 1 (0.92%)           | nan            | nan            |\n",
      "| ('First episode', 2)                           | 185 (94.87%)   | 84 (97.67%)    | 101 (92.66%)        | 57 (98.28%)    | 27 (96.43%)    |\n",
      "| ('First episode', 1)                           | 10 (5.13%)     | 2 (2.33%)      | 8 (7.34%)           | 1 (1.72%)      | 1 (3.57%)      |\n",
      "| ('Family history of psychiatric disorders', 2) | 162 (83.08%)   | 72 (83.72%)    | 90 (82.57%)         | 48 (82.76%)    | 24 (85.71%)    |\n",
      "| ('Family history of psychiatric disorders', 1) | 33 (16.92%)    | 14 (16.28%)    | 19 (17.43%)         | 10 (17.24%)    | 4 (14.29%)     |\n",
      "| ('Medication Strategies', 1)                   | 159 (81.54%)   | 68 (79.07%)    | 91 (83.49%)         | 50 (86.21%)    | 18 (64.29%)    |\n",
      "| ('Medication Strategies', 2)                   | 36 (18.46%)    | 18 (20.93%)    | 18 (16.51%)         | 8 (13.79%)     | 10 (35.71%)    |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './ouput/after preprocessing-195.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "continuous_fields = [\n",
    "    'PANSS_Negative', 'PANSS_Positive', 'PANSS_Affective',\n",
    "    'PANSS_Cognitive', 'PANSS-N', 'PANSS-P', 'PANSS-G', 'Age', 'Education_years', 'BMI',\n",
    "    'SES', 'RPM', 'Frequency of episodes', 'Age of onset', \n",
    "    'Illness of duration (months)', 'Illness of duration (years)', 'Dose Equivalent to Olanzapine (mg/d)'\n",
    "]\n",
    "\n",
    "categorical_fields = [\n",
    "    'Gender', 'Ethnic', 'Residence', 'Only_child',\n",
    "    'Smoking_status', 'Alcohol_consumption', 'Employed',\n",
    "    'Marital_status', 'First episode', \n",
    "    'Family history of psychiatric disorders',\"Medication Strategies\"\n",
    "]\n",
    "followed_up = df[df['follow-up'] == 1]\n",
    "lost_to_followup = df[df['follow-up'] == 0]\n",
    "remission = followed_up[followed_up['remissin_outcome'] == 1]\n",
    "no_remission = followed_up[followed_up['remissin_outcome'] == 2]\n",
    "\n",
    "def format_categorical_summary(series):\n",
    "    counts = series.value_counts()\n",
    "    percentages = series.value_counts(normalize=True).mul(100).round(2)\n",
    "    return counts.astype(str) + \" (\" + percentages.astype(str) + \"%)\"\n",
    "\n",
    "\n",
    "def calculate_summary(dataframe):\n",
    "    continuous_summary = dataframe[continuous_fields].agg(['mean', 'std']).transpose()\n",
    "    continuous_summary_formatted = continuous_summary.apply(lambda row: f\"{row['mean']:.2f} ± {row['std']:.2f}\", axis=1)\n",
    "    categorical_summary = pd.concat({field: format_categorical_summary(dataframe[field]) for field in categorical_fields})\n",
    "    return pd.concat([continuous_summary_formatted, categorical_summary], axis=0)\n",
    "\n",
    "all_samples_summary = calculate_summary(df)\n",
    "followed_up_summary = calculate_summary(followed_up)\n",
    "lost_to_followup_summary = calculate_summary(lost_to_followup)\n",
    "remission_summary = calculate_summary(remission)\n",
    "no_remission_summary = calculate_summary(no_remission)\n",
    "\n",
    "summaries = pd.concat({\n",
    "    'All Samples': all_samples_summary,\n",
    "    'Followed Up': followed_up_summary,\n",
    "    'Lost to Follow-Up': lost_to_followup_summary,\n",
    "    'Remission': remission_summary,\n",
    "    'No Remission': no_remission_summary\n",
    "}, axis=1)\n",
    "\n",
    "final_table = summaries.reset_index()\n",
    "final_table.columns = ['Field Name', 'All Samples', 'Followed Up', 'Lost to Follow-Up', 'Remission', 'No Remission']\n",
    "\n",
    "markdown_table = final_table.to_markdown(index=False)\n",
    "\n",
    "print(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正态和方差齐性检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_normality(group):\n",
    "    stat, p_value = shapiro(group)\n",
    "    return p_value > 0.05  \n",
    "\n",
    "def check_variance_equality(group1, group2):\n",
    "    stat, p_value = levene(group1, group2)\n",
    "    return p_value > 0.05  \n",
    "def calculate_p_values(group1, group2, fields):\n",
    "    p_values = {}\n",
    "    for field in fields:\n",
    "        if group1[field].nunique() > 1 and group2[field].nunique() > 1:\n",
    "            normal1 = check_normality(group1[field])\n",
    "            normal2 = check_normality(group2[field])\n",
    "            \n",
    "            equal_var = check_variance_equality(group1[field], group2[field]) if normal1 and normal2 else False\n",
    "            \n",
    "            stat, p_value = ttest_ind(group1[field], group2[field], equal_var=equal_var)\n",
    "            p_values[field] = p_value\n",
    "        else:\n",
    "            p_values[field] = None\n",
    "    return p_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 连续变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Field Name                                     | All Samples    | Followed Up    | Lost to Follow-Up   | Remission      | No Remission   | Follow-Up vs. Attrition p-value   | Remission vs. No Remission p-value   |\n",
      "|:-----------------------------------------------|:---------------|:---------------|:--------------------|:---------------|:---------------|:----------------------------------|:-------------------------------------|\n",
      "| PANSS_Negative                                 | 8.22 ± 2.50    | 8.38 ± 2.53    | 8.09 ± 2.49         | 8.23 ± 2.70    | 8.68 ± 2.13    | 0.427                             | 0.401                                |\n",
      "| PANSS_Positive                                 | 6.24 ± 1.75    | 6.07 ± 1.79    | 6.37 ± 1.70         | 6.05 ± 1.68    | 6.13 ± 2.04    | 0.247                             | 0.856                                |\n",
      "| PANSS_Affective                                | 5.65 ± 0.86    | 5.63 ± 0.88    | 5.67 ± 0.85         | 5.66 ± 0.92    | 5.58 ± 0.79    | 0.783                             | 0.679                                |\n",
      "| PANSS_Cognitive                                | 9.78 ± 1.72    | 9.68 ± 1.74    | 9.86 ± 1.71         | 9.64 ± 1.82    | 9.75 ± 1.61    | 0.459                             | 0.787                                |\n",
      "| PANSS-N                                        | 21.42 ± 6.50   | 21.76 ± 6.37   | 21.15 ± 6.62        | 21.53 ± 6.83   | 22.21 ± 5.37   | 0.516                             | 0.617                                |\n",
      "| PANSS-P                                        | 22.01 ± 4.47   | 21.57 ± 4.71   | 22.35 ± 4.26        | 21.69 ± 4.24   | 21.32 ± 5.65   | 0.234                             | 0.761                                |\n",
      "| PANSS-G                                        | 40.30 ± 6.83   | 40.07 ± 6.90   | 40.48 ± 6.80        | 39.72 ± 7.53   | 40.79 ± 5.39   | 0.681                             | 0.457                                |\n",
      "| Age                                            | 35.35 ± 9.35   | 34.47 ± 8.93   | 36.05 ± 9.66        | 34.33 ± 8.70   | 34.75 ± 9.56   | 0.238                             | 0.844                                |\n",
      "| Education_years                                | 11.12 ± 4.57   | 10.70 ± 4.05   | 11.46 ± 4.93        | 10.28 ± 3.81   | 11.57 ± 4.44   | 0.238                             | 0.192                                |\n",
      "| BMI                                            | 23.66 ± 3.73   | 23.21 ± 3.38   | 24.01 ± 3.97        | 23.48 ± 3.16   | 22.66 ± 3.79   | 0.133                             | 0.322                                |\n",
      "| SES                                            | 23.21 ± 7.32   | 22.88 ± 7.44   | 23.47 ± 7.26        | 22.52 ± 7.30   | 23.64 ± 7.79   | 0.583                             | 0.525                                |\n",
      "| RPM                                            | 32.56 ± 11.50  | 34.15 ± 11.67  | 31.31 ± 11.27       | 34.79 ± 11.21  | 32.82 ± 12.67  | 0.088                             | 0.486                                |\n",
      "| Frequency of episodes                          | 5.98 ± 4.27    | 6.22 ± 3.89    | 5.80 ± 4.56         | 6.17 ± 3.84    | 6.32 ± 4.05    | 0.486                             | 0.871                                |\n",
      "| Age of onset                                   | 27.43 ± 8.63   | 27.08 ± 8.46   | 27.71 ± 8.79        | 26.71 ± 7.94   | 27.86 ± 9.56   | 0.615                             | 0.584                                |\n",
      "| Illness of duration (months)                   | 116.92 ± 85.99 | 114.50 ± 78.09 | 118.83 ± 92.06      | 109.05 ± 71.78 | 125.79 ± 90.14 | 0.723                             | 0.395                                |\n",
      "| Illness of duration (years)                    | 9.74 ± 7.17    | 9.54 ± 6.51    | 9.90 ± 7.67         | 9.09 ± 5.98    | 10.48 ± 7.51   | 0.723                             | 0.395                                |\n",
      "| Dose Equivalent to Olanzapine (mg/d)           | 14.48 ± 6.41   | 15.07 ± 6.31   | 14.02 ± 6.47        | 14.30 ± 5.46   | 16.65 ± 7.66   | 0.255                             | 0.154                                |\n",
      "| ('Gender', 1)                                  | 114 (58.46%)   | 53 (61.63%)    | 61 (55.96%)         | 39 (67.24%)    | 14 (50.0%)     |                                   |                                      |\n",
      "| ('Gender', 2)                                  | 81 (41.54%)    | 33 (38.37%)    | 48 (44.04%)         | 19 (32.76%)    | 14 (50.0%)     |                                   |                                      |\n",
      "| ('Ethnic', 1)                                  | 173 (88.72%)   | 77 (89.53%)    | 96 (88.07%)         | 53 (91.38%)    | 24 (85.71%)    |                                   |                                      |\n",
      "| ('Ethnic', 2)                                  | 22 (11.28%)    | 9 (10.47%)     | 13 (11.93%)         | 5 (8.62%)      | 4 (14.29%)     |                                   |                                      |\n",
      "| ('Residence', 1)                               | 114 (58.46%)   | 44 (51.16%)    | 70 (64.22%)         | 27 (46.55%)    | 17 (60.71%)    |                                   |                                      |\n",
      "| ('Residence', 2)                               | 81 (41.54%)    | 42 (48.84%)    | 39 (35.78%)         | 31 (53.45%)    | 11 (39.29%)    |                                   |                                      |\n",
      "| ('Only_child', 2)                              | 132 (67.69%)   | 56 (65.12%)    | 76 (69.72%)         | 41 (70.69%)    | 15 (53.57%)    |                                   |                                      |\n",
      "| ('Only_child', 1)                              | 63 (32.31%)    | 30 (34.88%)    | 33 (30.28%)         | 17 (29.31%)    | 13 (46.43%)    |                                   |                                      |\n",
      "| ('Smoking_status', 1)                          | 119 (61.03%)   | 54 (62.79%)    | 65 (59.63%)         | 34 (58.62%)    | 20 (71.43%)    |                                   |                                      |\n",
      "| ('Smoking_status', 3)                          | 57 (29.23%)    | 24 (27.91%)    | 33 (30.28%)         | 18 (31.03%)    | 6 (21.43%)     |                                   |                                      |\n",
      "| ('Smoking_status', 2)                          | 19 (9.74%)     | 8 (9.3%)       | 11 (10.09%)         | 6 (10.34%)     | 2 (7.14%)      |                                   |                                      |\n",
      "| ('Alcohol_consumption', 1)                     | 133 (68.21%)   | 60 (69.77%)    | 73 (66.97%)         | 40 (68.97%)    | 20 (71.43%)    |                                   |                                      |\n",
      "| ('Alcohol_consumption', 2)                     | 54 (27.69%)    | 23 (26.74%)    | 31 (28.44%)         | 16 (27.59%)    | 7 (25.0%)      |                                   |                                      |\n",
      "| ('Alcohol_consumption', 3)                     | 8 (4.1%)       | 3 (3.49%)      | 5 (4.59%)           | 2 (3.45%)      | 1 (3.57%)      |                                   |                                      |\n",
      "| ('Employed', 2)                                | 142 (72.82%)   | 66 (76.74%)    | 76 (69.72%)         | 43 (74.14%)    | 23 (82.14%)    |                                   |                                      |\n",
      "| ('Employed', 1)                                | 53 (27.18%)    | 20 (23.26%)    | 33 (30.28%)         | 15 (25.86%)    | 5 (17.86%)     |                                   |                                      |\n",
      "| ('Marital_status', 1)                          | 115 (58.97%)   | 52 (60.47%)    | 63 (57.8%)          | 34 (58.62%)    | 18 (64.29%)    |                                   |                                      |\n",
      "| ('Marital_status', 2)                          | 48 (24.62%)    | 21 (24.42%)    | 27 (24.77%)         | 17 (29.31%)    | 4 (14.29%)     |                                   |                                      |\n",
      "| ('Marital_status', 3)                          | 31 (15.9%)     | 13 (15.12%)    | 18 (16.51%)         | 7 (12.07%)     | 6 (21.43%)     |                                   |                                      |\n",
      "| ('Marital_status', 4)                          | 1 (0.51%)      | nan            | 1 (0.92%)           | nan            | nan            |                                   |                                      |\n",
      "| ('First episode', 2)                           | 185 (94.87%)   | 84 (97.67%)    | 101 (92.66%)        | 57 (98.28%)    | 27 (96.43%)    |                                   |                                      |\n",
      "| ('First episode', 1)                           | 10 (5.13%)     | 2 (2.33%)      | 8 (7.34%)           | 1 (1.72%)      | 1 (3.57%)      |                                   |                                      |\n",
      "| ('Family history of psychiatric disorders', 2) | 162 (83.08%)   | 72 (83.72%)    | 90 (82.57%)         | 48 (82.76%)    | 24 (85.71%)    |                                   |                                      |\n",
      "| ('Family history of psychiatric disorders', 1) | 33 (16.92%)    | 14 (16.28%)    | 19 (17.43%)         | 10 (17.24%)    | 4 (14.29%)     |                                   |                                      |\n",
      "| ('Medication Strategies', 1)                   | 159 (81.54%)   | 68 (79.07%)    | 91 (83.49%)         | 50 (86.21%)    | 18 (64.29%)    |                                   |                                      |\n",
      "| ('Medication Strategies', 2)                   | 36 (18.46%)    | 18 (20.93%)    | 18 (16.51%)         | 8 (13.79%)     | 10 (35.71%)    |                                   |                                      |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def calculate_p_values(group1, group2, fields):\n",
    "    p_values = {}\n",
    "    for field in fields:\n",
    "        if group1[field].nunique() > 1 and group2[field].nunique() > 1:\n",
    "            stat, p_value = ttest_ind(group1[field], group2[field], equal_var=False)  # Welch's t-test\n",
    "            p_values[field] = p_value\n",
    "        else:\n",
    "            p_values[field] = None\n",
    "    return p_values\n",
    "\n",
    "followup_attrition_p_values = calculate_p_values(followed_up, lost_to_followup, continuous_fields)\n",
    "\n",
    "remission_no_remission_p_values = calculate_p_values(remission, no_remission, continuous_fields)\n",
    "\n",
    "final_table['Follow-Up vs. Attrition p-value'] = final_table['Field Name'].map(followup_attrition_p_values)\n",
    "final_table['Remission vs. No Remission p-value'] = final_table['Field Name'].map(remission_no_remission_p_values)\n",
    "\n",
    "final_table['Follow-Up vs. Attrition p-value'] = final_table['Follow-Up vs. Attrition p-value'].apply(lambda x: f\"{x:.3f}\" if pd.notnull(x) else \"\")\n",
    "final_table['Remission vs. No Remission p-value'] = final_table['Remission vs. No Remission p-value'].apply(lambda x: f\"{x:.3f}\" if pd.notnull(x) else \"\")\n",
    "\n",
    "markdown_table_with_pvalues = final_table.to_markdown(index=False)\n",
    "\n",
    "# Print the Markdown table with p-values\n",
    "print(markdown_table_with_pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Field                                                                      |   P-Value |\n",
      "|:---------------------------------------------------------------------------|----------:|\n",
      "| Gender (Followed Up vs Lost to Follow-Up)                                  | 0.466011  |\n",
      "| Ethnic (Followed Up vs Lost to Follow-Up)                                  | 0.822311  |\n",
      "| Residence (Followed Up vs Lost to Follow-Up)                               | 0.0794046 |\n",
      "| Only_child (Followed Up vs Lost to Follow-Up)                              | 0.538895  |\n",
      "| Employed (Followed Up vs Lost to Follow-Up)                                | 0.331315  |\n",
      "| First episode (Followed Up vs Lost to Follow-Up)                           | 0.189997  |\n",
      "| Family history of psychiatric disorders (Followed Up vs Lost to Follow-Up) | 0.850304  |\n",
      "| Gender (Remission vs No Remission)                                         | 0.157422  |\n",
      "| Ethnic (Remission vs No Remission)                                         | 0.464502  |\n",
      "| Residence (Remission vs No Remission)                                      | 0.254971  |\n",
      "| Only_child (Remission vs No Remission)                                     | 0.149532  |\n",
      "| Employed (Remission vs No Remission)                                       | 0.586876  |\n",
      "| First episode (Remission vs No Remission)                                  | 0.547743  |\n",
      "| Family history of psychiatric disorders (Remission vs No Remission)        | 1         |\n",
      "| Smoking_status (Followed Up vs Lost to Follow-Up)                          | 0.904147  |\n",
      "| Alcohol_consumption (Followed Up vs Lost to Follow-Up)                     | 0.883175  |\n",
      "| Smoking_status (Remission vs No Remission)                                 | 0.507892  |\n",
      "| Alcohol_consumption (Remission vs No Remission)                            | 0.968044  |\n",
      "| Marital_status (Followed Up vs Lost to Follow-Up)                          | 0.733202  |\n",
      "| Marital_status (Remission vs No Remission)                                 | 0.217155  |\n",
      "All expected frequencies are greater than 5.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "file_path = './ouput/after preprocessing-195.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "followed_up = df[df['follow-up'] == 1]  \n",
    "lost_to_followup = df[df['follow-up'] == 0]  # \n",
    "\n",
    "remission = followed_up[followed_up['remissin_outcome'] == 1]  \n",
    "no_remission = followed_up[followed_up['remissin_outcome'] == 2] \n",
    "\n",
    "\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "\n",
    "def calculate_p_value(crosstab):\n",
    "\n",
    "    if crosstab.shape == (2, 2):\n",
    "        _, p = fisher_exact(crosstab)\n",
    "    else:\n",
    "        chi2, p, dof, expected = chi2_contingency(crosstab)\n",
    "        \n",
    "        if (expected < 5).sum() > 0:\n",
    "            chi2, p, dof, expected = chi2_contingency(crosstab, lambda_=\"log-likelihood\")\n",
    "        else:\n",
    "            pass\n",
    "    return p\n",
    "\n",
    "\n",
    "p_values = {}\n",
    "\n",
    "\n",
    "binary_fields = ['Gender', 'Ethnic', 'Residence', 'Only_child', 'Employed', 'First episode', \n",
    "                 'Family history of psychiatric disorders']\n",
    "\n",
    "for field in binary_fields:\n",
    "    crosstab = pd.crosstab(df[field], df['follow-up'])\n",
    "    p_values[f\"{field} (Followed Up vs Lost to Follow-Up)\"] = calculate_p_value(crosstab)\n",
    "\n",
    "for field in binary_fields:\n",
    "    crosstab = pd.crosstab(followed_up[field], followed_up['remissin_outcome'])\n",
    "    p_values[f\"{field} (Remission vs No Remission)\"] = calculate_p_value(crosstab)\n",
    "\n",
    "ternary_fields = ['Smoking_status', 'Alcohol_consumption']\n",
    "\n",
    "for field in ternary_fields:\n",
    "    crosstab = pd.crosstab(df[field], df['follow-up'])\n",
    "    p_values[f\"{field} (Followed Up vs Lost to Follow-Up)\"] = calculate_p_value(crosstab)\n",
    "\n",
    "for field in ternary_fields:\n",
    "    crosstab = pd.crosstab(followed_up[field], followed_up['remissin_outcome'])\n",
    "    p_values[f\"{field} (Remission vs No Remission)\"] = calculate_p_value(crosstab)\n",
    "\n",
    "quaternary_fields = ['Marital_status']\n",
    "\n",
    "for field in quaternary_fields:\n",
    "    crosstab = pd.crosstab(df[field], df['follow-up'])\n",
    "    p_values[f\"{field} (Followed Up vs Lost to Follow-Up)\"] = calculate_p_value(crosstab)\n",
    "\n",
    "for field in quaternary_fields:\n",
    "    crosstab = pd.crosstab(followed_up[field], followed_up['remissin_outcome'])\n",
    "    p_values[f\"{field} (Remission vs No Remission)\"] = calculate_p_value(crosstab)\n",
    "\n",
    "p_values_df = pd.DataFrame(list(p_values.items()), columns=['Field', 'P-Value'])\n",
    "\n",
    "\n",
    "print(p_values_df.to_markdown(index=False))\n",
    "\n",
    "\n",
    "def check_chi2_assumptions(crosstab):\n",
    "    chi2, _, _, expected = stats.chi2_contingency(crosstab)\n",
    "    if (expected < 5).sum() > 0:\n",
    "        print(f\"Warning: There are cells with expected frequencies less than 5, chi2 test may not be valid.\\n\")\n",
    "        print(f\"Expected frequencies:\\n{expected}\")\n",
    "    else:\n",
    "        print(\"All expected frequencies are greater than 5.\")\n",
    "\n",
    "gender_crosstab = pd.crosstab(df['Gender'], df['follow-up'])\n",
    "check_chi2_assumptions(gender_crosstab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: First episode (Followed Up vs Lost to Follow-Up)\n",
      "Expected frequencies:\n",
      "[[  5.58974359   4.41025641]\n",
      " [103.41025641  81.58974359]]\n",
      "\n",
      "Field: Alcohol_consumption (Followed Up vs Lost to Follow-Up)\n",
      "Expected frequencies:\n",
      "[[74.34358974 58.65641026]\n",
      " [30.18461538 23.81538462]\n",
      " [ 4.47179487  3.52820513]]\n",
      "\n",
      "Field: Marital_status (Followed Up vs Lost to Follow-Up)\n",
      "Expected frequencies:\n",
      "[[64.28205128 50.71794872]\n",
      " [26.83076923 21.16923077]\n",
      " [17.32820513 13.67179487]\n",
      " [ 0.55897436  0.44102564]]\n",
      "\n",
      "Field: Ethnic (Remission vs No Remission)\n",
      "Expected frequencies:\n",
      "[[51.93023256 25.06976744]\n",
      " [ 6.06976744  2.93023256]]\n",
      "\n",
      "Field: First episode (Remission vs No Remission)\n",
      "Expected frequencies:\n",
      "[[ 1.34883721  0.65116279]\n",
      " [56.65116279 27.34883721]]\n",
      "\n",
      "Field: Family history of psychiatric disorders (Remission vs No Remission)\n",
      "Expected frequencies:\n",
      "[[ 9.44186047  4.55813953]\n",
      " [48.55813953 23.44186047]]\n",
      "\n",
      "Field: Smoking_status (Remission vs No Remission)\n",
      "Expected frequencies:\n",
      "[[36.41860465 17.58139535]\n",
      " [ 5.39534884  2.60465116]\n",
      " [16.18604651  7.81395349]]\n",
      "\n",
      "Field: Alcohol_consumption (Remission vs No Remission)\n",
      "Expected frequencies:\n",
      "[[40.46511628 19.53488372]\n",
      " [15.51162791  7.48837209]\n",
      " [ 2.02325581  0.97674419]]\n",
      "\n",
      "Field: Marital_status (Remission vs No Remission)\n",
      "Expected frequencies:\n",
      "[[35.06976744 16.93023256]\n",
      " [14.1627907   6.8372093 ]\n",
      " [ 8.76744186  4.23255814]]\n",
      "\n",
      "| Field                                                                      | Chi-squared Assumption Check                                    |\n",
      "|:---------------------------------------------------------------------------|:----------------------------------------------------------------|\n",
      "| Gender (Followed Up vs Lost to Follow-Up)                                  | All expected frequencies are greater than 5.                    |\n",
      "| Ethnic (Followed Up vs Lost to Follow-Up)                                  | All expected frequencies are greater than 5.                    |\n",
      "| Residence (Followed Up vs Lost to Follow-Up)                               | All expected frequencies are greater than 5.                    |\n",
      "| Only_child (Followed Up vs Lost to Follow-Up)                              | All expected frequencies are greater than 5.                    |\n",
      "| Employed (Followed Up vs Lost to Follow-Up)                                | All expected frequencies are greater than 5.                    |\n",
      "| First episode (Followed Up vs Lost to Follow-Up)                           | Warning: There are cells with expected frequencies less than 5. |\n",
      "| Family history of psychiatric disorders (Followed Up vs Lost to Follow-Up) | All expected frequencies are greater than 5.                    |\n",
      "| Smoking_status (Followed Up vs Lost to Follow-Up)                          | All expected frequencies are greater than 5.                    |\n",
      "| Alcohol_consumption (Followed Up vs Lost to Follow-Up)                     | Warning: There are cells with expected frequencies less than 5. |\n",
      "| Marital_status (Followed Up vs Lost to Follow-Up)                          | Warning: There are cells with expected frequencies less than 5. |\n",
      "| Gender (Remission vs No Remission)                                         | All expected frequencies are greater than 5.                    |\n",
      "| Ethnic (Remission vs No Remission)                                         | Warning: There are cells with expected frequencies less than 5. |\n",
      "| Residence (Remission vs No Remission)                                      | All expected frequencies are greater than 5.                    |\n",
      "| Only_child (Remission vs No Remission)                                     | All expected frequencies are greater than 5.                    |\n",
      "| Employed (Remission vs No Remission)                                       | All expected frequencies are greater than 5.                    |\n",
      "| First episode (Remission vs No Remission)                                  | Warning: There are cells with expected frequencies less than 5. |\n",
      "| Family history of psychiatric disorders (Remission vs No Remission)        | Warning: There are cells with expected frequencies less than 5. |\n",
      "| Smoking_status (Remission vs No Remission)                                 | Warning: There are cells with expected frequencies less than 5. |\n",
      "| Alcohol_consumption (Remission vs No Remission)                            | Warning: There are cells with expected frequencies less than 5. |\n",
      "| Marital_status (Remission vs No Remission)                                 | Warning: There are cells with expected frequencies less than 5. |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "def check_chi2_assumptions(crosstab):\n",
    "    chi2, _, _, expected = stats.chi2_contingency(crosstab)\n",
    "    if (expected < 5).sum() > 0:\n",
    "        message = f\"Warning: There are cells with expected frequencies less than 5.\"\n",
    "        expected_freq = expected\n",
    "    else:\n",
    "        message = \"All expected frequencies are greater than 5.\"\n",
    "        expected_freq = None\n",
    "    return message, expected_freq\n",
    "\n",
    "assumption_checks = {}\n",
    "\n",
    "all_fields = binary_fields + ternary_fields + quaternary_fields\n",
    "\n",
    "for field in all_fields:\n",
    "    crosstab = pd.crosstab(df[field], df['follow-up'])\n",
    "    message, expected_freq = check_chi2_assumptions(crosstab)\n",
    "    assumption_checks[f\"{field} (Followed Up vs Lost to Follow-Up)\"] = message\n",
    "    if expected_freq is not None:\n",
    "        print(f\"Field: {field} (Followed Up vs Lost to Follow-Up)\")\n",
    "        print(f\"Expected frequencies:\\n{expected_freq}\\n\")\n",
    "\n",
    "\n",
    "for field in all_fields:\n",
    "    crosstab = pd.crosstab(followed_up[field], followed_up['remissin_outcome'])\n",
    "    message, expected_freq = check_chi2_assumptions(crosstab)\n",
    "    assumption_checks[f\"{field} (Remission vs No Remission)\"] = message\n",
    "    if expected_freq is not None:\n",
    "        print(f\"Field: {field} (Remission vs No Remission)\")\n",
    "        print(f\"Expected frequencies:\\n{expected_freq}\\n\")\n",
    "\n",
    "assumption_checks_df = pd.DataFrame(list(assumption_checks.items()), columns=['Field', 'Chi-squared Assumption Check'])\n",
    "\n",
    "print(assumption_checks_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.药物用量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195人组（所有的被试） - 单一药物使用情况：\n",
      "   Type of antipsychotic medication  使用人数                     剂量范围\n",
      "0                      Aripiprazole     9      10.00, 18.33, 30.00\n",
      "1                       Amisulpride    14  200.00, 514.29, 1000.00\n",
      "2                    Chlorpromazine     1   250.00, 250.00, 250.00\n",
      "3                         Clozapine    17    50.00, 230.88, 400.00\n",
      "4                        Olanzapine    26       2.00, 17.58, 20.00\n",
      "5                      Paliperidone    11        3.30, 6.85, 12.00\n",
      "6                       Perospirone     5      18.00, 30.40, 42.00\n",
      "7                        Quetiapine     7   150.00, 314.29, 600.00\n",
      "8                       Risperidone    59         2.50, 4.59, 6.00\n",
      "9                         Sulpiride     5   600.00, 640.00, 800.00\n",
      "10                      Ziprasidone     5    80.00, 128.00, 160.00\n",
      "195人组（所有的被试） - 联合药物使用情况：\n",
      "          Type of antipsychotic medication  使用人数                    剂量范围\n",
      "0                   Aripiprazole_Clozapine     2    20.00, 69.38, 200.00\n",
      "1                  Aripiprazole_Olanzapine     1     15.00, 17.50, 20.00\n",
      "2       Aripiprazole_Risperidone_Buspirone     1     10.00, 10.00, 10.00\n",
      "3                   Amisulpride_Olanzapine     3   10.00, 191.67, 400.00\n",
      "4                    Clozapine_Amisulpride     1  200.00, 225.00, 250.00\n",
      "5           Magnesium Valproate_Olanzapine     1  10.00, 505.00, 1000.00\n",
      "6                     Olanzapine_Buspirone     1     20.00, 25.00, 30.00\n",
      "7                   Olanzapine_Risperidone     7       2.00, 8.43, 20.00\n",
      "8                     Olanzapine_Sulpiride     1   10.00, 305.00, 600.00\n",
      "9                 Paliperidone_Perospirone     1       6.00, 9.00, 12.00\n",
      "10                Perospirone_Paliperidone     1       3.30, 7.65, 12.00\n",
      "11               Risperidone_ Aripiprazole     1       4.00, 7.00, 10.00\n",
      "12                 Risperidone_Amisulpride     1    6.00, 203.00, 400.00\n",
      "13                   Risperidone_Clozapine     1    4.00, 102.00, 200.00\n",
      "14                  Risperidone_Olanzapine     6      2.00, 10.38, 25.00\n",
      "15  Risperidone_Oxcarbazepine_Tandospirone     1   5.00, 411.67, 1200.00\n",
      "16                  Risperidone_Quetiapine     3    2.00, 102.83, 300.00\n",
      "17                   Risperidone_Sulpiride     1    4.00, 302.00, 600.00\n",
      "18                   Sulpiride_Perospirone     1    8.00, 304.00, 600.00\n",
      "19                  Ziprasidone_Olanzapine     1     20.00, 30.00, 40.00\n",
      "\n",
      "\n",
      "被追踪组 - 单一药物使用情况：\n",
      "  Type of antipsychotic medication  使用人数                     剂量范围\n",
      "0                     Aripiprazole     6      10.00, 19.17, 30.00\n",
      "1                      Amisulpride     9  300.00, 555.56, 1000.00\n",
      "2                        Clozapine     6   125.00, 229.17, 400.00\n",
      "3                       Olanzapine    10      10.00, 18.50, 20.00\n",
      "4                     Paliperidone     8         3.30, 6.41, 9.00\n",
      "5                      Perospirone     3      18.00, 32.00, 42.00\n",
      "6                       Quetiapine     2   200.00, 250.00, 300.00\n",
      "7                      Risperidone    20         4.00, 4.55, 6.00\n",
      "8                        Sulpiride     2   600.00, 600.00, 600.00\n",
      "9                      Ziprasidone     2    80.00, 120.00, 160.00\n",
      "被追踪组 - 联合药物使用情况：\n",
      "       Type of antipsychotic medication  使用人数                    剂量范围\n",
      "0                Aripiprazole_Clozapine     2    20.00, 69.38, 200.00\n",
      "1    Aripiprazole_Risperidone_Buspirone     1     10.00, 10.00, 10.00\n",
      "2                Amisulpride_Olanzapine     1   20.00, 210.00, 400.00\n",
      "3                 Clozapine_Amisulpride     1  200.00, 225.00, 250.00\n",
      "4                  Olanzapine_Buspirone     1     20.00, 25.00, 30.00\n",
      "5                Olanzapine_Risperidone     3       2.00, 8.67, 20.00\n",
      "6                  Olanzapine_Sulpiride     1   10.00, 305.00, 600.00\n",
      "7              Paliperidone_Perospirone     1       6.00, 9.00, 12.00\n",
      "8             Risperidone_ Aripiprazole     1       4.00, 7.00, 10.00\n",
      "9                Risperidone_Olanzapine     2      4.00, 12.00, 20.00\n",
      "10               Risperidone_Quetiapine     3    2.00, 102.83, 300.00\n",
      "11                Sulpiride_Perospirone     1    8.00, 304.00, 600.00\n",
      "\n",
      "\n",
      "流失组 - 单一药物使用情况：\n",
      "   Type of antipsychotic medication  使用人数                    剂量范围\n",
      "0                      Aripiprazole     3     10.00, 16.67, 20.00\n",
      "1                       Amisulpride     5  200.00, 440.00, 600.00\n",
      "2                    Chlorpromazine     1  250.00, 250.00, 250.00\n",
      "3                         Clozapine    11   50.00, 231.82, 400.00\n",
      "4                        Olanzapine    16      2.00, 17.00, 20.00\n",
      "5                      Paliperidone     3       6.00, 8.00, 12.00\n",
      "6                       Perospirone     2     20.00, 28.00, 36.00\n",
      "7                        Quetiapine     5  150.00, 340.00, 600.00\n",
      "8                       Risperidone    39        2.50, 4.62, 6.00\n",
      "9                         Sulpiride     3  600.00, 666.67, 800.00\n",
      "10                      Ziprasidone     3  120.00, 133.33, 160.00\n",
      "流失组 - 联合药物使用情况：\n",
      "          Type of antipsychotic medication  使用人数                    剂量范围\n",
      "0                  Aripiprazole_Olanzapine     1     15.00, 17.50, 20.00\n",
      "1                   Amisulpride_Olanzapine     2   10.00, 182.50, 400.00\n",
      "2           Magnesium Valproate_Olanzapine     1  10.00, 505.00, 1000.00\n",
      "3                   Olanzapine_Risperidone     4       2.00, 8.25, 20.00\n",
      "4                 Perospirone_Paliperidone     1       3.30, 7.65, 12.00\n",
      "5                  Risperidone_Amisulpride     1    6.00, 203.00, 400.00\n",
      "6                    Risperidone_Clozapine     1    4.00, 102.00, 200.00\n",
      "7                   Risperidone_Olanzapine     4       2.00, 9.56, 25.00\n",
      "8   Risperidone_Oxcarbazepine_Tandospirone     1   5.00, 411.67, 1200.00\n",
      "9                    Risperidone_Sulpiride     1    4.00, 302.00, 600.00\n",
      "10                  Ziprasidone_Olanzapine     1     20.00, 30.00, 40.00\n",
      "\n",
      "\n",
      "缓解组 - 单一药物使用情况：\n",
      "  Type of antipsychotic medication  使用人数                     剂量范围\n",
      "0                     Aripiprazole     4      10.00, 20.00, 30.00\n",
      "1                      Amisulpride     6  400.00, 616.67, 1000.00\n",
      "2                        Clozapine     5   125.00, 235.00, 400.00\n",
      "3                       Olanzapine     6      15.00, 19.17, 20.00\n",
      "4                     Paliperidone     5         6.00, 6.60, 9.00\n",
      "5                      Perospirone     1      42.00, 42.00, 42.00\n",
      "6                       Quetiapine     1   200.00, 200.00, 200.00\n",
      "7                      Risperidone    18         4.00, 4.56, 6.00\n",
      "8                        Sulpiride     2   600.00, 600.00, 600.00\n",
      "9                      Ziprasidone     2    80.00, 120.00, 160.00\n",
      "缓解组 - 联合药物使用情况：\n",
      "  Type of antipsychotic medication  使用人数                    剂量范围\n",
      "0           Aripiprazole_Clozapine     2    20.00, 69.38, 200.00\n",
      "1            Clozapine_Amisulpride     1  200.00, 225.00, 250.00\n",
      "2           Olanzapine_Risperidone     1       5.00, 7.50, 10.00\n",
      "3         Paliperidone_Perospirone     1       6.00, 9.00, 12.00\n",
      "4        Risperidone_ Aripiprazole     1       4.00, 7.00, 10.00\n",
      "5           Risperidone_Olanzapine     1      4.00, 12.00, 20.00\n",
      "6           Risperidone_Quetiapine     1    6.00, 153.00, 300.00\n",
      "\n",
      "\n",
      "未缓解组 - 单一药物使用情况：\n",
      "  Type of antipsychotic medication  使用人数                    剂量范围\n",
      "0                     Aripiprazole     2     15.00, 17.50, 20.00\n",
      "1                      Amisulpride     3  300.00, 433.33, 600.00\n",
      "2                        Clozapine     1  200.00, 200.00, 200.00\n",
      "3                       Olanzapine     4     10.00, 17.50, 20.00\n",
      "4                     Paliperidone     3        3.30, 6.10, 9.00\n",
      "5                      Perospirone     2     18.00, 27.00, 36.00\n",
      "6                       Quetiapine     1  300.00, 300.00, 300.00\n",
      "7                      Risperidone     2        4.00, 4.50, 5.00\n",
      "未缓解组 - 联合药物使用情况：\n",
      "      Type of antipsychotic medication  使用人数                   剂量范围\n",
      "0   Aripiprazole_Risperidone_Buspirone     1    10.00, 10.00, 10.00\n",
      "1               Amisulpride_Olanzapine     1  20.00, 210.00, 400.00\n",
      "2                 Olanzapine_Buspirone     1    20.00, 25.00, 30.00\n",
      "3               Olanzapine_Risperidone     2      2.00, 9.25, 20.00\n",
      "4                 Olanzapine_Sulpiride     1  10.00, 305.00, 600.00\n",
      "5               Risperidone_Olanzapine     1     4.00, 12.00, 20.00\n",
      "6               Risperidone_Quetiapine     2    2.00, 77.75, 300.00\n",
      "7                Sulpiride_Perospirone     1   8.00, 304.00, 600.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = './rawdata/195.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "df['Dose of antipsychotic drugs (mg/day)'] = df['Dose of antipsychotic drugs (mg/day)'].astype(str)\n",
    "\n",
    "def calculate_stats(group):\n",
    "    monotherapy_df = group.loc[group['Type of antipsychotic medication'].str.count('_') == 0].copy()\n",
    "    monotherapy_df['Dose of antipsychotic drugs (mg/day)'] = monotherapy_df['Dose of antipsychotic drugs (mg/day)'].astype(float)\n",
    "    monotherapy_stats = monotherapy_df.groupby('Type of antipsychotic medication').agg(\n",
    "        使用人数=('Dose of antipsychotic drugs (mg/day)', 'count'),\n",
    "        最小计量=('Dose of antipsychotic drugs (mg/day)', 'min'),\n",
    "        平均计量=('Dose of antipsychotic drugs (mg/day)', 'mean'),\n",
    "        最大计量=('Dose of antipsychotic drugs (mg/day)', 'max')\n",
    "    ).round(2) \n",
    "    monotherapy_stats['剂量范围'] = monotherapy_stats.apply(\n",
    "        lambda x: f\"{x['最小计量']:.2f}, {x['平均计量']:.2f}, {x['最大计量']:.2f}\", axis=1\n",
    "    )\n",
    "    monotherapy_stats.reset_index(inplace=True)\n",
    "\n",
    "    combination_therapy_df = group.loc[group['Type of antipsychotic medication'].str.count('_') > 0].copy()\n",
    "    doses_per_patient = combination_therapy_df['Dose of antipsychotic drugs (mg/day)'].str.split('_').tolist()\n",
    "    expanded_doses = pd.DataFrame(doses_per_patient, index=combination_therapy_df.index)\n",
    "    expanded_doses = expanded_doses.stack().reset_index(level=1, drop=True).astype(float)\n",
    "    expanded_doses.name = 'Dose of antipsychotic drugs (mg/day)'\n",
    "    combination_therapy_df = combination_therapy_df.drop('Dose of antipsychotic drugs (mg/day)', axis=1)\n",
    "    combination_therapy_df = combination_therapy_df.join(expanded_doses)\n",
    "    combination_therapy_stats = combination_therapy_df.groupby('Type of antipsychotic medication').agg(\n",
    "        使用人数=('ID', 'nunique'),\n",
    "        最小计量=('Dose of antipsychotic drugs (mg/day)', 'min'),\n",
    "        平均计量=('Dose of antipsychotic drugs (mg/day)', 'mean'),\n",
    "        最大计量=('Dose of antipsychotic drugs (mg/day)', 'max')\n",
    "    ).round(2) \n",
    "    combination_therapy_stats['剂量范围'] = combination_therapy_stats.apply(\n",
    "        lambda x: f\"{x['最小计量']:.2f}, {x['平均计量']:.2f}, {x['最大计量']:.2f}\", axis=1\n",
    "    )\n",
    "    combination_therapy_stats.reset_index(inplace=True)\n",
    "\n",
    "    monotherapy_stats = monotherapy_stats[['Type of antipsychotic medication', '使用人数', '剂量范围']]\n",
    "    combination_therapy_stats = combination_therapy_stats[['Type of antipsychotic medication', '使用人数', '剂量范围']]\n",
    "\n",
    "    return monotherapy_stats, combination_therapy_stats\n",
    "\n",
    "all_monotherapy_stats, all_combination_therapy_stats = calculate_stats(df)\n",
    "\n",
    "followed_df = df[df['follow-up'] == 1]\n",
    "followed_monotherapy_stats, followed_combination_therapy_stats = calculate_stats(followed_df)\n",
    "\n",
    "lost_df = df[df['follow-up'] == 0]\n",
    "lost_monotherapy_stats, lost_combination_therapy_stats = calculate_stats(lost_df)\n",
    "\n",
    "remission_df = df[df['remissin_outcome'] == 1]\n",
    "remission_monotherapy_stats, remission_combination_therapy_stats = calculate_stats(remission_df)\n",
    "\n",
    "non_remission_df = df[df['remissin_outcome'] == 2]\n",
    "non_remission_monotherapy_stats, non_remission_combination_therapy_stats = calculate_stats(non_remission_df)\n",
    "\n",
    "def print_stats(title, mono_stats, combo_stats):\n",
    "    print(f\"{title} - 单一药物使用情况：\")\n",
    "    print(mono_stats)\n",
    "    print(f\"{title} - 联合药物使用情况：\")\n",
    "    print(combo_stats)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print_stats(\"195人组（所有的被试）\", all_monotherapy_stats, all_combination_therapy_stats)\n",
    "print_stats(\"被追踪组\", followed_monotherapy_stats, followed_combination_therapy_stats)\n",
    "print_stats(\"流失组\", lost_monotherapy_stats, lost_combination_therapy_stats)\n",
    "print_stats(\"缓解组\", remission_monotherapy_stats, remission_combination_therapy_stats)\n",
    "print_stats(\"未缓解组\", non_remission_monotherapy_stats, non_remission_combination_therapy_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195人组（所有的被试） - 单一药物使用总人数: 159\n",
      "195人组（所有的被试） - 联合药物使用总人数: 36\n",
      "195人组（所有的被试） - 字段总人数: 195\n",
      "195人组（所有的被试） - 单一药物和联合药物的使用人数总和是否等于总人数: True\n",
      "---\n",
      "\n",
      "被追踪组 - 单一药物使用总人数: 68\n",
      "被追踪组 - 联合药物使用总人数: 18\n",
      "被追踪组 - 字段总人数: 86\n",
      "被追踪组 - 单一药物和联合药物的使用人数总和是否等于总人数: True\n",
      "---\n",
      "\n",
      "流失组 - 单一药物使用总人数: 91\n",
      "流失组 - 联合药物使用总人数: 18\n",
      "流失组 - 字段总人数: 109\n",
      "流失组 - 单一药物和联合药物的使用人数总和是否等于总人数: True\n",
      "---\n",
      "\n",
      "缓解组 - 单一药物使用总人数: 50\n",
      "缓解组 - 联合药物使用总人数: 8\n",
      "缓解组 - 字段总人数: 58\n",
      "缓解组 - 单一药物和联合药物的使用人数总和是否等于总人数: True\n",
      "---\n",
      "\n",
      "未缓解组 - 单一药物使用总人数: 18\n",
      "未缓解组 - 联合药物使用总人数: 10\n",
      "未缓解组 - 字段总人数: 28\n",
      "未缓解组 - 单一药物和联合药物的使用人数总和是否等于总人数: True\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_totals(group_df, group_mono_stats, group_combo_stats, group_name):\n",
    "    monotherapy_total = group_mono_stats['使用人数'].sum()\n",
    "\n",
    "    combination_therapy_total = group_combo_stats['使用人数'].sum()\n",
    "\n",
    "    total_unique_patients = group_df['ID'].nunique()\n",
    "\n",
    "    total_patients_check = (monotherapy_total + combination_therapy_total) == total_unique_patients\n",
    "\n",
    "    print(f\"{group_name} - 单一药物使用总人数: {monotherapy_total}\")\n",
    "    print(f\"{group_name} - 联合药物使用总人数: {combination_therapy_total}\")\n",
    "    print(f\"{group_name} - 字段总人数: {total_unique_patients}\")\n",
    "    print(f\"{group_name} - 单一药物和联合药物的使用人数总和是否等于总人数: {total_patients_check}\")\n",
    "    print(\"---\\n\")\n",
    "\n",
    "check_totals(df, all_monotherapy_stats, all_combination_therapy_stats, \"195人组（所有的被试）\")\n",
    "check_totals(followed_df, followed_monotherapy_stats, followed_combination_therapy_stats, \"被追踪组\")\n",
    "check_totals(lost_df, lost_monotherapy_stats, lost_combination_therapy_stats, \"流失组\")\n",
    "check_totals(remission_df, remission_monotherapy_stats, remission_combination_therapy_stats, \"缓解组\")\n",
    "check_totals(non_remission_df, non_remission_monotherapy_stats, non_remission_combination_therapy_stats, \"未缓解组\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.流失样本(n=109)与追踪到的样本(n=86) 基线水平差异检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 连续变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Variable  Test Statistic   p-Value  \\\n",
      "0         Stroop_incongruent_rt     5283.000000  0.128038   \n",
      "1           Stroop_congruent_rt     5504.000000  0.036917   \n",
      "2             Stroop_neutral_rt     5224.000000  0.170343   \n",
      "3    Stroop_interference_effect     5217.000000  0.175988   \n",
      "4                        Go_acc     4148.500000  0.169091   \n",
      "5                         Go_rt     5005.000000  0.417127   \n",
      "6                      Nogo_acc     5099.000000  0.292644   \n",
      "7                   Switch_cost     4410.000000  0.479793   \n",
      "8                   Mixing_cost        0.232188  0.816687   \n",
      "9                   RM_1750_acc     4206.000000  0.218887   \n",
      "10                   RM_750_acc     4281.000000  0.299519   \n",
      "11                    DSBT_Span     4277.000000  0.284263   \n",
      "12                          RPM     5337.000000  0.096774   \n",
      "13                     CBT_Span     4874.500000  0.623042   \n",
      "14                      CBT_acc     4878.000000  0.621457   \n",
      "15               PANSS_Negative        0.795577  0.427318   \n",
      "16               PANSS_Positive       -1.161406  0.247032   \n",
      "17              PANSS_Affective     4615.000000  0.855011   \n",
      "18              PANSS_Cognitive     4404.000000  0.470314   \n",
      "19                      PANSS-N        0.651531  0.515510   \n",
      "20                      PANSS-P     4319.500000  0.346588   \n",
      "21                      PANSS-G     4501.000000  0.634925   \n",
      "22                          Age     4281.000000  0.299684   \n",
      "23              Education_years     4155.000000  0.170137   \n",
      "24                          BMI     4223.500000  0.236683   \n",
      "25                          SES     4390.500000  0.448757   \n",
      "26                 Age of onset     4555.000000  0.736556   \n",
      "27  Illness of duration (years)     4729.500000  0.914402   \n",
      "28                           IF     5216.000000  0.176805   \n",
      "29                          EFF     4487.000000  0.610156   \n",
      "30                          IUF     5219.000000  0.174361   \n",
      "31                          ISF     4488.000000  0.611948   \n",
      "32                           US     4412.000000  0.482976   \n",
      "\n",
      "    Mean Difference (followed-lost)       Test Type  Corrected p-Value  \\\n",
      "0                         28.253223  Mann-Whitney U           0.618098   \n",
      "1                         38.275727  Mann-Whitney U           0.618098   \n",
      "2                         22.842316  Mann-Whitney U           0.618098   \n",
      "3                         15.433411  Mann-Whitney U           0.618098   \n",
      "4                         -0.034932  Mann-Whitney U           0.618098   \n",
      "5                          6.388946  Mann-Whitney U           0.692966   \n",
      "6                          0.009933  Mann-Whitney U           0.618098   \n",
      "7                        -43.908685  Mann-Whitney U           0.692966   \n",
      "8                          6.540355          t-test           0.869377   \n",
      "9                         -0.032304  Mann-Whitney U           0.618098   \n",
      "10                        -0.040799  Mann-Whitney U           0.618098   \n",
      "11                        -0.098464  Mann-Whitney U           0.618098   \n",
      "12                         2.839236  Mann-Whitney U           0.618098   \n",
      "13                         0.044291  Mann-Whitney U           0.722501   \n",
      "14                         0.005579  Mann-Whitney U           0.722501   \n",
      "15                         0.288153          t-test           0.692966   \n",
      "16                        -0.293910          t-test           0.618098   \n",
      "17                        -0.034488  Mann-Whitney U           0.881730   \n",
      "18                        -0.184968  Mann-Whitney U           0.692966   \n",
      "19                         0.609025          t-test           0.708826   \n",
      "20                        -0.778856  Mann-Whitney U           0.672789   \n",
      "21                        -0.407297  Mann-Whitney U           0.722501   \n",
      "22                        -1.580755  Mann-Whitney U           0.618098   \n",
      "23                        -0.761041  Mann-Whitney U           0.618098   \n",
      "24                        -0.794798  Mann-Whitney U           0.618098   \n",
      "25                        -0.584169  Mann-Whitney U           0.692966   \n",
      "26                        -0.625027  Mann-Whitney U           0.810212   \n",
      "27                        -0.360474  Mann-Whitney U           0.914402   \n",
      "28                         7.721672  Mann-Whitney U           0.618098   \n",
      "29                       -12.073105  Mann-Whitney U           0.722501   \n",
      "30                         3.844684  Mann-Whitney U           0.618098   \n",
      "31                       -18.093506  Mann-Whitney U           0.722501   \n",
      "32                       -21.970494  Mann-Whitney U           0.692966   \n",
      "\n",
      "    Significant After Correction  \n",
      "0                          False  \n",
      "1                          False  \n",
      "2                          False  \n",
      "3                          False  \n",
      "4                          False  \n",
      "5                          False  \n",
      "6                          False  \n",
      "7                          False  \n",
      "8                          False  \n",
      "9                          False  \n",
      "10                         False  \n",
      "11                         False  \n",
      "12                         False  \n",
      "13                         False  \n",
      "14                         False  \n",
      "15                         False  \n",
      "16                         False  \n",
      "17                         False  \n",
      "18                         False  \n",
      "19                         False  \n",
      "20                         False  \n",
      "21                         False  \n",
      "22                         False  \n",
      "23                         False  \n",
      "24                         False  \n",
      "25                         False  \n",
      "26                         False  \n",
      "27                         False  \n",
      "28                         False  \n",
      "29                         False  \n",
      "30                         False  \n",
      "31                         False  \n",
      "32                         False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "df = pd.read_excel('./ouput/after preprocessing-195.xlsx') \n",
    "\n",
    "continuous_variables = [\n",
    "    'Stroop_incongruent_rt', 'Stroop_congruent_rt', 'Stroop_neutral_rt',\n",
    "    'Stroop_interference_effect', 'Go_acc', 'Go_rt', 'Nogo_acc',\n",
    "    'Switch_cost', 'Mixing_cost', 'RM_1750_acc', 'RM_750_acc',\n",
    "    'DSBT_Span', 'RPM', 'CBT_Span', 'CBT_acc', 'PANSS_Negative',\n",
    "    'PANSS_Positive', 'PANSS_Affective', 'PANSS_Cognitive', 'PANSS-N',\n",
    "    'PANSS-P', 'PANSS-G', 'Age', 'Education_years', 'BMI', 'SES',\n",
    "    'Age of onset', 'Illness of duration (years)', 'IF', 'EFF', 'IUF',\n",
    "    'ISF', 'US'\n",
    "]\n",
    "\n",
    "followed_df = df[df['follow-up'] == 1]\n",
    "lost_df = df[df['follow-up'] == 0]\n",
    "\n",
    "results = []\n",
    "\n",
    "for var in continuous_variables:\n",
    "\n",
    "    sw_followed = stats.shapiro(followed_df[var].dropna())\n",
    "    sw_lost = stats.shapiro(lost_df[var].dropna())\n",
    "    \n",
    "    if (sw_followed.pvalue > 0.05) and (sw_lost.pvalue > 0.05):\n",
    "        test_stat, p_value = stats.ttest_ind(followed_df[var].dropna(), lost_df[var].dropna(), equal_var=False)  # Welch's t-test\n",
    "    else:\n",
    "        test_stat, p_value = stats.mannwhitneyu(followed_df[var].dropna(), lost_df[var].dropna())\n",
    "    \n",
    "    results.append({\n",
    "        'Variable': var,\n",
    "        'Test Statistic': test_stat,\n",
    "        'p-Value': p_value,\n",
    "        'Mean Difference (followed-lost)': followed_df[var].mean() - lost_df[var].mean(),\n",
    "        'Test Type': 't-test' if (sw_followed.pvalue > 0.05) and (sw_lost.pvalue > 0.05) else 'Mann-Whitney U'\n",
    "    })\n",
    "\n",
    "p_values = [r['p-Value'] for r in results]\n",
    "\n",
    "rejections, corrected_p_values, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
    "for i, result in enumerate(results):\n",
    "    result['Corrected p-Value'] = corrected_p_values[i]\n",
    "    result['Significant After Correction'] = rejections[i]\n",
    "\n",
    "corrected_results_df = pd.DataFrame(results)\n",
    "\n",
    "print(corrected_results_df)\n",
    "\n",
    "corrected_results_df.to_excel('./ouput/sample_selection_bias_analysis_corrected.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 分类变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 特殊处理的变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.回归掉社会人口后患者与对照组的EF差异检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./rawdata/残差结果.xlsx')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['Stroop_incongruent_rt', 'Stroop_congruent_rt', 'Stroop_neutral_rt', 'Stroop_interference effect_rt', 'Go_acc', 'Go_rt', 'Nogo_acc', 'Switch_cost', 'Mixing_cost', 'RM-1,750_acc', 'RM-750_acc', 'DSBT_Span', 'CBT_Span', 'CBT_acc', 'IF', 'EFF', 'IUF', 'ISF', 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Stroop_incongruent_rt:\n",
      "SCZ group mean±std dev = 2.65 ± 15.81\n",
      "HC group mean±std dev = -2.65 ± 17.25\n",
      "t = 3.116, p = 0.002, Cohen's d = 0.321\n",
      "\n",
      "Variable Stroop_congruent_rt:\n",
      "SCZ group mean±std dev = 2.53 ± 11.00\n",
      "HC group mean±std dev = -2.53 ± 11.03\n",
      "t = 4.461, p < 0.001, Cohen's d = 0.459\n",
      "\n",
      "Variable Stroop_neutral_rt:\n",
      "SCZ group mean±std dev = 2.18 ± 9.00\n",
      "HC group mean±std dev = -2.18 ± 8.30\n",
      "t = 4.891, p < 0.001, Cohen's d = 0.503\n",
      "\n",
      "Variable Stroop_interference effect_rt:\n",
      "SCZ group mean±std dev = -76.86 ± 1444.13\n",
      "HC group mean±std dev = 76.86 ± 1010.08\n",
      "t = -1.199, p = 0.231, Cohen's d = -0.123\n",
      "\n",
      "Variable Go_acc:\n",
      "SCZ group mean±std dev = -0.01 ± 0.02\n",
      "HC group mean±std dev = 0.01 ± 0.02\n",
      "t = -7.001, p < 0.001, Cohen's d = -0.720\n",
      "\n",
      "Variable Go_rt:\n",
      "SCZ group mean±std dev = 2.17 ± 7.08\n",
      "HC group mean±std dev = -2.17 ± 6.27\n",
      "t = 6.318, p < 0.001, Cohen's d = 0.650\n",
      "\n",
      "Variable Nogo_acc:\n",
      "SCZ group mean±std dev = -0.00 ± 0.03\n",
      "HC group mean±std dev = 0.00 ± 0.03\n",
      "t = -1.313, p = 0.190, Cohen's d = -0.135\n",
      "\n",
      "Variable Switch_cost:\n",
      "SCZ group mean±std dev = 1.52 ± 10.77\n",
      "HC group mean±std dev = -1.52 ± 8.23\n",
      "t = 3.092, p = 0.002, Cohen's d = 0.318\n",
      "\n",
      "Variable Mixing_cost:\n",
      "SCZ group mean±std dev = -11.88 ± 210.33\n",
      "HC group mean±std dev = 11.88 ± 175.49\n",
      "t = -1.192, p = 0.234, Cohen's d = -0.123\n",
      "\n",
      "Variable RM-1,750_acc:\n",
      "SCZ group mean±std dev = -0.03 ± 0.19\n",
      "HC group mean±std dev = 0.03 ± 0.17\n",
      "t = -3.076, p = 0.002, Cohen's d = -0.316\n",
      "\n",
      "Variable RM-750_acc:\n",
      "SCZ group mean±std dev = -0.03 ± 0.26\n",
      "HC group mean±std dev = 0.03 ± 0.19\n",
      "t = -2.670, p = 0.008, Cohen's d = -0.275\n",
      "\n",
      "Variable DSBT_Span:\n",
      "SCZ group mean±std dev = -0.25 ± 1.19\n",
      "HC group mean±std dev = 0.25 ± 1.11\n",
      "t = -4.245, p < 0.001, Cohen's d = -0.437\n",
      "\n",
      "Variable CBT_Span:\n",
      "SCZ group mean±std dev = -0.04 ± 1.01\n",
      "HC group mean±std dev = 0.04 ± 1.12\n",
      "t = -0.711, p = 0.478, Cohen's d = -0.073\n",
      "\n",
      "Variable CBT_acc:\n",
      "SCZ group mean±std dev = -0.00 ± 0.14\n",
      "HC group mean±std dev = 0.00 ± 0.15\n",
      "t = -0.306, p = 0.760, Cohen's d = -0.031\n",
      "\n",
      "Variable IF:\n",
      "SCZ group mean±std dev = -28.05 ± 527.30\n",
      "HC group mean±std dev = 28.05 ± 369.56\n",
      "t = -1.198, p = 0.232, Cohen's d = -0.123\n",
      "\n",
      "Variable EFF:\n",
      "SCZ group mean±std dev = 1.08 ± 8.34\n",
      "HC group mean±std dev = -1.08 ± 6.19\n",
      "t = 2.854, p = 0.005, Cohen's d = 0.294\n",
      "\n",
      "Variable IUF:\n",
      "SCZ group mean±std dev = -10.48 ± 193.67\n",
      "HC group mean±std dev = 10.48 ± 135.89\n",
      "t = -1.218, p = 0.224, Cohen's d = -0.125\n",
      "\n",
      "Variable ISF:\n",
      "SCZ group mean±std dev = 1.32 ± 10.24\n",
      "HC group mean±std dev = -1.32 ± 7.60\n",
      "t = 2.855, p = 0.005, Cohen's d = 0.294\n",
      "\n",
      "Variable US:\n",
      "SCZ group mean±std dev = 1.10 ± 7.81\n",
      "HC group mean±std dev = -1.10 ± 5.97\n",
      "t = 3.092, p = 0.002, Cohen's d = 0.318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from numpy import std, mean, sqrt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cohens_d(group1, group2):\n",
    "    \"\"\"\n",
    "    Compute Cohen's d.\n",
    "    \n",
    "    group1: Series or NumPy array\n",
    "    group2: Series or NumPy array\n",
    "    \n",
    "    returns a float (Cohen's d)\n",
    "    \"\"\"\n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1 = group1.var()\n",
    "    var2 = group2.var()\n",
    "\n",
    "\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "    \n",
    "\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Variable', 'SCZ Mean', 'SCZ Std Dev', 'HC Mean', 'HC Std Dev', 't', 'p', 'Cohen\\'s d'])\n",
    "\n",
    "\n",
    "for col in numeric_cols:\n",
    "    scz = df[df['Group'] == 1][col]\n",
    "    hc = df[df['Group'] == 2][col]\n",
    "    \n",
    "    t_stat, p_val = ttest_ind(scz, hc)\n",
    "    \n",
    "    d = cohens_d(scz, hc)\n",
    "    if p_val < 0.001:\n",
    "        p_val_str = \"p < 0.001\"\n",
    "    else:\n",
    "        p_val_str = f\"p = {p_val:.3f}\"\n",
    "    \n",
    "    print(f'Variable {col}:\\nSCZ group mean±std dev = {scz.mean():.2f} ± {scz.std():.2f}\\nHC group mean±std dev = {hc.mean():.2f} ± {hc.std():.2f}\\nt = {t_stat:.3f}, {p_val_str}, Cohen\\'s d = {d:.3f}\\n')\n",
    "    \n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'Variable': [col],\n",
    "        'SCZ Mean': [scz.mean()],\n",
    "        'SCZ Std Dev': [scz.std()],\n",
    "        'HC Mean': [hc.mean()],\n",
    "        'HC Std Dev': [hc.std()],\n",
    "        't': [t_stat],\n",
    "        'p': [p_val_str],\n",
    "        'Cohen\\'s d': [d]\n",
    "    })\n",
    "\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "results_df.to_excel('./ouput/EF回归掉社会人口后是否差异显著.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Variable                  | SCZ的均值 ± 标准差          | HC的均值 ± 标准差          | t       | p         | d       |\n",
      "|---------------------------|-----------------------------|-----------------------------|---------|-----------|---------|\n",
      "| Stroop_incongruent_rt | 2.65 ± 15.81 | -2.65 ± 17.25 | 3.116 | p = 0.002 | 0.321 |\n",
      "| Stroop_congruent_rt | 2.53 ± 11.00 | -2.53 ± 11.03 | 4.461 | p < 0.001 | 0.459 |\n",
      "| Stroop_neutral_rt | 2.18 ± 9.00 | -2.18 ± 8.30 | 4.891 | p < 0.001 | 0.503 |\n",
      "| Stroop_interference effect_rt | -76.86 ± 1444.13 | 76.86 ± 1010.08 | -1.199 | p = 0.231 | -0.123 |\n",
      "| Go_acc | -0.01 ± 0.02 | 0.01 ± 0.02 | -7.001 | p < 0.001 | -0.720 |\n",
      "| Go_rt | 2.17 ± 7.08 | -2.17 ± 6.27 | 6.318 | p < 0.001 | 0.650 |\n",
      "| Nogo_acc | -0.00 ± 0.03 | 0.00 ± 0.03 | -1.313 | p = 0.190 | -0.135 |\n",
      "| Switch_cost | 1.52 ± 10.77 | -1.52 ± 8.23 | 3.092 | p = 0.002 | 0.318 |\n",
      "| Mixing_cost | -11.88 ± 210.33 | 11.88 ± 175.49 | -1.192 | p = 0.234 | -0.123 |\n",
      "| RM-1,750_acc | -0.03 ± 0.19 | 0.03 ± 0.17 | -3.076 | p = 0.002 | -0.316 |\n",
      "| RM-750_acc | -0.03 ± 0.26 | 0.03 ± 0.19 | -2.670 | p = 0.008 | -0.275 |\n",
      "| DSBT_Span | -0.25 ± 1.19 | 0.25 ± 1.11 | -4.245 | p < 0.001 | -0.437 |\n",
      "| CBT_Span | -0.04 ± 1.01 | 0.04 ± 1.12 | -0.711 | p = 0.478 | -0.073 |\n",
      "| CBT_acc | -0.00 ± 0.14 | 0.00 ± 0.15 | -0.306 | p = 0.760 | -0.031 |\n",
      "| IF | -28.05 ± 527.30 | 28.05 ± 369.56 | -1.198 | p = 0.232 | -0.123 |\n",
      "| EFF | 1.08 ± 8.34 | -1.08 ± 6.19 | 2.854 | p = 0.005 | 0.294 |\n",
      "| IUF | -10.48 ± 193.67 | 10.48 ± 135.89 | -1.218 | p = 0.224 | -0.125 |\n",
      "| ISF | 1.32 ± 10.24 | -1.32 ± 7.60 | 2.855 | p = 0.005 | 0.294 |\n",
      "| US | 1.10 ± 7.81 | -1.10 ± 5.97 | 3.092 | p = 0.002 | 0.318 |\n"
     ]
    }
   ],
   "source": [
    "print(\"| Variable                  | SCZ的均值 ± 标准差          | HC的均值 ± 标准差          | t       | p         | d       |\")\n",
    "print(\"|---------------------------|-----------------------------|-----------------------------|---------|-----------|---------|\")\n",
    "\n",
    "for index, row in results_df.iterrows():\n",
    "    cohens_d = row[\"Cohen's d\"]\n",
    "    print(f\"| {row['Variable']} | {row['SCZ Mean']:.2f} ± {row['SCZ Std Dev']:.2f} | {row['HC Mean']:.2f} ± {row['HC Std Dev']:.2f} | {row['t']:.3f} | {row['p']} | {cohens_d:.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.全部完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据分析全部完成！\n"
     ]
    }
   ],
   "source": [
    "print(\"数据分析全部完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
